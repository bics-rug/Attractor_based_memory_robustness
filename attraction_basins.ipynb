{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "currentdir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, currentdir) \n",
    "sys.path.insert(0, parentdir) \n",
    "sys.path.insert(0, currentdir + \"\\Code\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtains and analyzes trajectories under weight noise, including number of fixed points and angular errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cmap = 'gray'\\nrc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\\nrc('text', usetex=True)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sklearn.decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import cm\n",
    "from matplotlib import rc\n",
    "import matplotlib as mpl\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "from scipy.integrate import odeint, DOP853, solve_ivp\n",
    "from scipy.stats import special_ortho_group\n",
    "from itertools import chain, combinations, permutations\n",
    "import seaborn as sns\n",
    "\n",
    "from ring_functions_noorman import *\n",
    "\n",
    "\"\"\"cmap = 'gray'\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symmetric cosine weight matrix W sym jk = JI + JE cos(theta_j - theta_K)\n",
    "# where JE and JI respectively control the strength of the tuned and untuned components of recurrent connectivity between neurons with preferred headings theta_j and theta_k.\n",
    "\n",
    "# For a network of size N , there are N 3 such “optimal” values of local excitation J*E\n",
    "\n",
    "# The parameters (JI, JE) can be set such that this system will generate a population profile that qualitatively looks like a discretely sampled “bump” of activity.\n",
    "# (JI, JE) are within the subset  \\Omega = \\OmegaJI\\times\\OmegaJE \\subset (−1, 1) \\times (2,1)\n",
    "\n",
    "def get_corners(N, m):\n",
    "    #works for even N\n",
    "    corners = []\n",
    "    corner_0 = np.array([m]*N)\n",
    "    corner_0[int(N/2):] *= -1\n",
    "    corner_0[int(N/2)-int(N/4):int(N/2)] = 0\n",
    "    corner_0[N-int(N/4):] = 0\n",
    "    for support_j in range(N):\n",
    "        corners.append(np.roll(corner_0, support_j))\n",
    "    corners = np.array(corners)\n",
    "    return corners\n",
    "\n",
    "def get_bumps_along_oneside_ring(N, m, corners, step_size=0.1):\n",
    "    x = np.arange(0, m+step_size, step_size)\n",
    "    n_xs = x.shape[0]\n",
    "    bumps = np.zeros((N, n_xs))\n",
    "    for i, x_i in enumerate(x):\n",
    "        for j in range(N):\n",
    "            bumps[j,i] = np.interp(x_i, [0,m], [corners[0][j],corners[1][j]])\n",
    "    return bumps\n",
    "\n",
    "def get_all_bumps(N, bumps):\n",
    "    all_bumps = []\n",
    "    for support_j in range(N):\n",
    "        for bump_i in range(bumps.shape[1]):\n",
    "            all_bumps.append(np.roll(bumps[:,bump_i], support_j))\n",
    "    all_bumps = np.array(all_bumps)\n",
    "    return all_bumps\n",
    "\n",
    "def get_all_bumps_2darray(N, bumps):\n",
    "    all_bumps = np.zeros((N,bumps.shape[1],N))\n",
    "    for support_j in range(N):\n",
    "        for bump_i in range(bumps.shape[1]):\n",
    "            all_bumps[support_j,bump_i] = np.roll(bumps[:,bump_i], support_j)\n",
    "    return all_bumps\n",
    "\n",
    "def get_noorman_symmetric_weights(N, J_I = 1, J_E = 1):\n",
    "    # W sym jk = JI + JE cos(theta_j - theta_K)\n",
    "    x = np.arange(0,N,1)\n",
    "    row = J_I + J_E*np.cos(2*np.pi*x/N)\n",
    "    W = scipy.linalg.circulant(row)\n",
    "    return W\n",
    "\n",
    "\n",
    "# W asym jk =sin(theta_j - theta_k)\n",
    "def get_noorman_asymmetric_weights(N):\n",
    "    # W asym jk =sin(theta_j - theta_k)\n",
    "    x = np.arange(0,N,1)\n",
    "    row = np.sin(2*np.pi*x/N)\n",
    "    W = scipy.linalg.circulant(row)\n",
    "    return W\n",
    "\n",
    "def noorman_ode(t,x,tau,transfer_function,W_sym,W_asym,c_ff,N):\n",
    "    \"\"\"Differential equation of head direction network in Noorman et al., 2022. \n",
    "    tau: integration constant\n",
    "    transfer_function: each neuron transforms its inputs via a nonlinear transfer function\n",
    "    W_sym, W_asym: symmetric and asymmetric weight matrices\n",
    "    v_in: input\n",
    "    c_ff: a constant feedforward input to all neurons in the network\n",
    "    N: number of neurons in the network\n",
    "    \"\"\"\n",
    "\n",
    "    return (-x + np.dot(W_sym+v_in(t)*W_asym, transfer_function(x))/N + c_ff)/tau\n",
    "\n",
    "def noorman_ode_with_noise(t,x,tau,transfer_function,W_sym,W_asym,c_ff,N,noises):\n",
    "    \"\"\"Differential equation of head direction network in Noorman et al., 2022. \n",
    "    tau: integration constant\n",
    "    transfer_function: each neuron transforms its inputs via a nonlinear transfer function\n",
    "    W_sym, W_asym: symmetric and asymmetric weight matrices\n",
    "    v_in: input\n",
    "    c_ff: a constant feedforward input to all neurons in the network\n",
    "    N: number of neurons in the network\n",
    "    \"\"\"\n",
    "    if noises is not None:\n",
    "        return (-x + np.dot(W_sym+v_in(t)*W_asym, transfer_function(x))/N + c_ff + noises[round(t)])/tau\n",
    "    else:\n",
    "        return (-x + np.dot(W_sym+v_in(t)*W_asym, transfer_function(x))/N + c_ff)/tau\n",
    "\n",
    "#Bump perturbations\n",
    "def noorman_ode_pert(t,x,tau,transfer_function,W_sym,W_asym,c_ff,N,center,rotation_mat,amplitude,b):\n",
    "    \"\"\"\n",
    "    create ODE for Noorman ring attractor with a local bump perturbation\n",
    "    center,rotation_mat,amplitude,b are set\n",
    "    \"\"\"\n",
    "    vector_bump = bump_perturbation(x, center, rotation_mat, amplitude, b)\n",
    "    noor = noorman_ode(t,x,tau,transfer_function,W_sym,W_asym,c_ff,N)\n",
    "    return noor + vector_bump\n",
    "\n",
    "def noorman_ode_Npert(t,x,tau,transfer_function,W_sym,W_asym,c_ff,N,Nbumps):\n",
    "    \"\"\"\n",
    "    create ODE for Noorman ring attractor with Nbumps local bump perturbations\n",
    "    for each bump: center,rotation_mat,amplitude,b are random\n",
    "    \"\"\"\n",
    "    noorode = noorman_ode(t,x,tau,transfer_function,W_sym,W_asym,c_ff,N)\n",
    "    for bi in range(Nbumps):\n",
    "        bump_i = np.random.randint(bumps.shape[0]) \n",
    "        roll_j = np.random.randint(N)\n",
    "        center = np.roll(bumps[:,bump_i], roll_j).copy()\n",
    "        rotation_mat = special_ortho_group.rvs(N)\n",
    "        amplitude = np.random.rand()\n",
    "        b = np.random.rand()\n",
    "        noorode += bump_perturbation(x, center, rotation_mat, amplitude, b)\n",
    "\n",
    "    return noorode\n",
    "\n",
    "# Fixed points and their stabilities\n",
    "def noorman_jacobian(x, W_sym):\n",
    "    N = W_sym.shape[0]\n",
    "    \n",
    "    r = np.where(x>0)\n",
    "    W_sub = np.zeros((N,N))\n",
    "    W_sub[:,r] = W_sym[:,r]\n",
    "    J = -np.eye(N)\n",
    "    J += W_sub/N\n",
    "    return J\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "def noorman_fixed_points(W_sym, c_ff):\n",
    "    \"\"\"\n",
    "    Takes as argument all the parameters of the recurrent part of the model (W_sym, c_ff)\n",
    "    \\dot x = -x + 1/N W_sym ReLU(x) + c_ff = 0\n",
    "    \"\"\"\n",
    "    fixed_point_list = []\n",
    "\n",
    "    N = W_sym.shape[0]\n",
    "    subsets = powerset(range(N))\n",
    "    for support in subsets:\n",
    "        if support == ():\n",
    "            continue\n",
    "        r = np.array(support)\n",
    "        \n",
    "        W_sub = np.zeros((N,N))\n",
    "        W_sub[:,r] = W_sym[:,r]\n",
    "        A = W_sub/N - np.eye(N)\n",
    "        fixed_point = -np.dot(np.linalg.inv(A), np.ones(N)*c_ff)\n",
    "        \n",
    "        #check true fixed point\n",
    "        negativity_condition = True\n",
    "        # print(r, [item for item in range(N) if item not in r])\n",
    "        for i in r:\n",
    "            if fixed_point[i] <= 0:\n",
    "                negativity_condition = False\n",
    "        for i in [item for item in range(N) if item not in r]:\n",
    "            if fixed_point[i] >= 0:\n",
    "                negativity_condition = False\n",
    "        \n",
    "        if negativity_condition:\n",
    "            fixed_point_list.append(fixed_point)\n",
    "        \n",
    "    fixed_point_array = np.array(fixed_point_list)\n",
    "    return fixed_point_array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def bump_perturbation(x, center, rotation_mat, amplitude, b=1):\n",
    "    \"\"\"\n",
    "    Perturbation is composed of parallel vector field \n",
    "    with the location given by center, \n",
    "    the norm of the vectors determined by a bump function\n",
    "    and the orientation given by theta\n",
    "    \n",
    "    x.shape = (Numberofpoints,N)\n",
    "    rotation_mat: orientation of perturbation\n",
    "    implemented for N-dimensional systems\n",
    "    \"\"\"\n",
    "    N = x.shape[0]\n",
    "    vector_bump = np.zeros(N)\n",
    "    vector_bump[0] = 1.\n",
    "    rotation_mat = special_ortho_group.rvs(N)\n",
    "    vector_bump = np.dot(vector_bump, rotation_mat)\n",
    "    vector_bump = np.multiply(vector_bump, bump_function(x, center=center, amplitude=amplitude, b=b))\n",
    "    \n",
    "    return vector_bump\n",
    "\n",
    "# we will take phi(·) to be threshold linear\n",
    "\n",
    "def v_in(t):\n",
    "    return 0\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.where(x<0,0,x)\n",
    "\n",
    "\n",
    "# # circle_in_vectorspace = \n",
    "\n",
    "# # #create points on hypersphere as:\n",
    "# # 1. take p=[1, 0, ... 0]\n",
    "# # 2. rotate point(s) along next axis ????\n",
    "\n",
    "# def fibonacci_sphere(samples=1000):\n",
    "\n",
    "#     points = []\n",
    "#     phi = math.pi * (math.sqrt(5.) - 1.)  # golden angle in radians\n",
    "\n",
    "#     for i in range(samples):\n",
    "#         y = 1 - (i / float(samples - 1)) * 2  # y goes from 1 to -1\n",
    "#         radius = math.sqrt(1 - y * y)  # radius at y\n",
    "\n",
    "#         theta = phi * i  # golden angle increment\n",
    "\n",
    "#         x = math.cos(theta) * radius\n",
    "#         z = math.sin(theta) * radius\n",
    "\n",
    "#         points.append((x, y, z))\n",
    "\n",
    "#     return points\n",
    "\n",
    "def hypersphere_lattice(n_points, n_dim):\n",
    "    \"\"\"\n",
    "    Generate a lattice of points on an N-dimensional hypersphere.\n",
    "    \"\"\"\n",
    "    points = np.random.uniform(-1, 1, size=(n_points, n_dim))\n",
    "    norms = np.linalg.norm(points, axis=1)\n",
    "    normalized_points = points / norms[:, np.newaxis]\n",
    "    return normalized_points\n",
    "\n",
    "def uniform_hypersphere_points(n_points, n_dim):\n",
    "    \"\"\"\n",
    "    Generate a lattice of points on an N-dimensional hypersphere.\n",
    "    \"\"\"\n",
    "    points = np.zeros((n_points, n_dim))\n",
    "    for i in range(n_points):\n",
    "        vec_0 = np.zeros((n_dim))\n",
    "        vec_0[0] = 1\n",
    "        points[i, :] = np.dot(special_ortho_group.rvs(n_dim), vec_0)\n",
    "\n",
    "    return points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1331)\n",
    "\n",
    "tau = 1\n",
    "transfer_function = ReLU\n",
    "N = 20\n",
    "J_I = -2.4\n",
    "J_E = 5\n",
    "W_sym = get_noorman_symmetric_weights(N, J_I, J_E)\n",
    "W_asym = get_noorman_asymmetric_weights(N)\n",
    "c_ff = 1.\n",
    "\n",
    "maxT = 100\n",
    "n_timesteps = 100\n",
    "t = np.linspace(0, maxT, n_timesteps)\n",
    "\n",
    "y0 = np.random.uniform(0,1,N)\n",
    "\n",
    "sol = solve_ivp(noorman_ode, y0=y0,  t_span=[0,maxT], t_eval=t, args=tuple([tau, transfer_function, W_sym, W_asym, c_ff, N]),dense_output=True)\n",
    "\n",
    "m = np.max(sol.sol(t)) # m #round? what should the maximum be according to the paper?\n",
    "corners = get_corners(N, m)\n",
    "bumps = get_bumps_along_oneside_ring(N, m, corners, step_size=0.05)\n",
    "step_size = .1\n",
    "x = np.arange(0, m+step_size, step_size)\n",
    "all_bumps = get_all_bumps(N, bumps)\n",
    "all_bumps_2d = get_all_bumps_2darray(N,bumps)\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.25, rc={\"lines.linewidth\": 1})\n",
    "fig, axs = plt.subplots(1, 1, figsize=(15, 8), sharex=True, sharey=True)\n",
    "axs.imshow(sol.sol(t))\n",
    "axs.set_xlabel(\"Time\")\n",
    "axs.set_ylabel(\"Neurons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectories(starting_points,W_sym_with_noise):\n",
    "    sols = np.zeros((len(starting_points), t.shape[0], N))\n",
    "    noises=None\n",
    "    for i, starting_point in enumerate(starting_points):\n",
    "        sol = solve_ivp(noorman_ode_with_noise, y0=starting_point,  t_span=[0,maxT], t_eval=t, args=tuple([tau, transfer_function, W_sym_with_noise, W_asym, c_ff, N, noises]),dense_output=True)\n",
    "        sols[i] = sol.sol(t).T\n",
    "    return sols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectories_per_sphere_radius(base_sphere,radius):\n",
    "    sphere = base_sphere * radius\n",
    "    seeds = [27, 0, 3, 13, 418, 1550] #33->0\n",
    "    norms =  [1e-10, 1e-5, 1e-1, .5, 1, 1.1, 1.5]\n",
    "\n",
    "    all_trajectories = {}\n",
    "    for seed in seeds:\n",
    "        for norm in norms:\n",
    "            np.random.seed(seed)\n",
    "            eps = np.random.uniform(-1,1,(N,N))\n",
    "            eps /= np.linalg.norm(eps)\n",
    "            eps *= norm\n",
    "\n",
    "            fixed_points = noorman_fixed_points(W_sym+eps, c_ff)\n",
    "            fixed_points = fixed_points[:-1] # exclude last fixed point which is not on the ring\n",
    "\n",
    "            trajectories_per_network = [] # shape (n_fixed_points,n_sphere_points,timesteps,N)\n",
    "            # for each fixed point, create a sphere of points around it, from which to start trajectories\n",
    "            for fixed_point in fixed_points:\n",
    "                starting_points = fixed_point + sphere\n",
    "                trajectories_per_fixed_point = get_trajectories(starting_points,W_sym+eps)\n",
    "                trajectories_per_network.append(trajectories_per_fixed_point)\n",
    "        \n",
    "            all_trajectories[(seed,norm)] = np.array(trajectories_per_network)\n",
    "    with open(\"results//basin_of_attraction//trajectories_{}.pkl\".format(radius), \"wb\") as f:\n",
    "        pickle.dump(all_trajectories, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = N\n",
    "n_sphere_points = 2\n",
    "base_sphere = uniform_hypersphere_points(n_sphere_points, n_dim)\n",
    "\n",
    "for radius in [1000000]:\n",
    "    print(radius)\n",
    "    get_trajectories_per_sphere_radius(base_sphere,radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [27, 0, 3, 13, 418, 1550] #33->0\n",
    "norms =  [1e-10, 1e-5, 1e-1, .5, 1, 1.1, 1.5]\n",
    "for radius in range(20):\n",
    "    with open(\"results//basin_of_attraction//trajectories_{}.pkl\".format(radius), \"rb\") as f:\n",
    "        trajectories_all_seeds_and_norms = pickle.load(f)\n",
    "    with open(\"results//weight_noise//N6//{}//fixed_points.pkl\".format(J_E), \"rb\") as f:\n",
    "        fixed_points_all = pickle.load(f)\n",
    "    with open(\"results//weight_noise//N6//{}//stable_points.pkl\".format(J_E), \"rb\") as f:\n",
    "        stable_points_all = pickle.load(f)\n",
    "    with open(\"results//weight_noise//N6//{}//saddle_points.pkl\".format(J_E), \"rb\") as f:\n",
    "        saddle_points_all = pickle.load(f)\n",
    "\n",
    "    for seed in seeds:\n",
    "        for norm in norms:\n",
    "            # trajectories_per_network shape (n_fixed_points,n_starting_points,timesteps,N)\n",
    "            trajectories_per_network = trajectories_all_seeds_and_norms[(seed,norm)]\n",
    "            # fixed_points shape (n_fixed_points,N)\n",
    "            fixed_points = fixed_points_all[(seed,norm)]\n",
    "            stable_points = stable_points_all[(seed,norm)]\n",
    "            saddle_points = saddle_points_all[(seed,norm)]\n",
    "            n_fixed_points = fixed_points.shape[0]\n",
    "\n",
    "            for i in range(n_fixed_points):\n",
    "                fixed_point = fixed_points[i]\n",
    "                if fixed_point in stable_points:\n",
    "                    # trajectories_per_fixed_point shape (n_starting_points,timesteps,N)\n",
    "                    trajectories_per_fixed_point = trajectories_per_network[i]\n",
    "                    # dist shape (n_starting_points,timesteps)\n",
    "                    \"\"\"\n",
    "                    # check whether trajectory location is approaching fixed point. This is not ideal, because although the trajectory starting point was defined based on a sphere around this fixed point, \n",
    "                    # the sphere radius might be big enough that the starting point is closest to another fixed point or it just goes towards its normal projection to the manifold, not necessarily to a fixed point\n",
    "                    dist = np.linalg.norm(trajectories_per_fixed_point-fixed_point,axis=-1) \n",
    "                    \"\"\"\n",
    "                    speed = np.linalg.norm(trajectories_per_fixed_point[:,1:,:] - trajectories_per_fixed_point[:,:-1,:],axis=2) # check whether trajectory speed is decreasing\n",
    "                    if speed[-1] - speed[0] >= 0:\n",
    "                        print(\"Trajectory speed not decreasing for seed {} norm {} fixed point index {}\".format(seed,norm,i))\n",
    "                    # optional: save all speeds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory(radius,seed,norm,fixed_point_idx,starting_point_idx,intermediate_timestep,sols):\n",
    "\n",
    "    with open(\"results//basin_of_attraction//trajectories_{}.pkl\".format(radius), \"rb\") as f:\n",
    "        trajectories_all_seeds_and_norms = pickle.load(f)\n",
    "    with open(\"results//weight_noise//N6//{}//fixed_points.pkl\".format(J_E), \"rb\") as f:\n",
    "        fixed_points_all = pickle.load(f)\n",
    "    with open(\"results//weight_noise//N6//{}//stable_points.pkl\".format(J_E), \"rb\") as f:\n",
    "        stable_points_all = pickle.load(f)\n",
    "    with open(\"results//weight_noise//N6//{}//saddle_points.pkl\".format(J_E), \"rb\") as f:\n",
    "        saddle_points_all = pickle.load(f)\n",
    "\n",
    "    trajectories_per_fixed_point = trajectories_all_seeds_and_norms[(seed,norm)][fixed_point_idx][starting_point_idx]\n",
    "    fixed_points = fixed_points_all[(seed,norm)]\n",
    "    stable_points = stable_points_all[(seed,norm)]\n",
    "    saddle_points = saddle_points_all[(seed,norm)]\n",
    "    print(trajectories_per_fixed_point.shape)\n",
    "\n",
    "    pca = sklearn.decomposition.PCA(n_components=2)\n",
    "\n",
    "    fixed_points_proj = pca.fit_transform(fixed_points.reshape(-1,N))\n",
    "    corners_proj = pca.transform(corners)\n",
    "\n",
    "    final_trajectory_state_proj = pca.transform(trajectories_per_fixed_point[-1].reshape(-1,N))\n",
    "    initial_trajectory_state_proj = pca.transform(trajectories_per_fixed_point[0].reshape(-1,N))\n",
    "    intermediate_trajectory_state_proj = pca.transform(trajectories_per_fixed_point[intermediate_timestep].reshape(-1,N))\n",
    "\n",
    "    for i in range(N):\n",
    "        plt.plot([corners_proj[i-1,0], corners_proj[i,0]],\n",
    "                [corners_proj[i-1,1], corners_proj[i,1]],\n",
    "                'k', label=\"Original attractor\", zorder=0, alpha=0.1, linewidth=10, \n",
    "                solid_capstyle='round')\n",
    "        \n",
    "    for i in range(fixed_points.shape[0]):\n",
    "        if fixed_points[i] in stable_points:\n",
    "            plt.plot(fixed_points_proj[i,0], fixed_points_proj[i,1], '*', color=\"darkblue\", label=\"Stable\", zorder=10, alpha=1., markersize=5) # final states of the trajectories \n",
    "        elif fixed_points[i] in saddle_points:\n",
    "            plt.plot(fixed_points_proj[i,0], fixed_points_proj[i,1], '*', color=\"darkorange\", label=\"Stable\", zorder=10, alpha=1., markersize=5) # final states of the trajectories \n",
    "\n",
    "        \n",
    "    #plt.plot(fixed_point_proj[:,0], fixed_point_proj[:,1], '^b', label=\"Stable\", zorder=10, alpha=1., markersize=20) # final states of the trajectories \n",
    "    plt.plot(initial_trajectory_state_proj[:,0], initial_trajectory_state_proj[:,1], '.g', label=\"Stable\", zorder=10, alpha=1., markersize=10) # final states of the trajectories \n",
    "    #plt.plot(intermediate_trajectory_state_proj[:,0], intermediate_trajectory_state_proj[:,1], '.m', label=\"Stable\", zorder=10, alpha=1., markersize=10) # final states of the trajectories \n",
    "    plt.plot(final_trajectory_state_proj[:,0], final_trajectory_state_proj[:,1], '.r', label=\"Stable\", zorder=10, alpha=1., markersize=10) # final states of the trajectories \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=seeds[0]\n",
    "norm=norms[0]\n",
    "fixed_point_idx=1\n",
    "starting_point_idx=5\n",
    "intermediate_timestep=8\n",
    "radius=9\n",
    "plot_trajectory(radius,seed,norm,fixed_point_idx,starting_point_idx,intermediate_timestep,sols[3])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SNN_PC_Multicomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
